#Reviewer B 

- A large part of the criticism in this review is grounded on
the assumption that we claim our core language to be good 
for dependently typed programming (DTP); when in fact we do not
support feature A, B or C, which is crutial for DTP. 

*This assumption is false*: we do not claim that our core language
is good for DTP. Moreover we also state some (though perhaps not
all) of the reasons why the language is limited for the kind of 
DTP available in Agda/Idris/Coq....

For example, the reviewer states:

”In particular, the comparisons suggest that the goal of the proposed
language is dependently-typed programming, as in Cayenne, Idris, Coq
or Agda”

whereas in the introduction, we clearly say that:

“A **non-goal** of the current work (although a worthy avenue for
future work) is to use λμ⋆ as a core language for modern dependently
typed languages like Agda or Idris”

We will rephrase the sentences that lead to the confusion if the
reviewer is kind enough to tell us which are the culprit sentences.

The reviewer also has a large paragraph complaining about missing 
features from FC and useful for DTP:

“* The core language lacks expressiveness for dependently-typed
programming and is not as expressive as FC.”

It is true that certain features of FC cannot be expressed, 
*but this is acknowledged in the paper*. For example, in related 
work we say:

"... there are still many important aspects of Haskell that we have
not modeled in λµ? . *One feature that requires further study is
GADTs*.  Many GADT definitions require injectivity of type
constructors, as well as equality constraints.  Because datatypes are
not built-in to λµ? , injectivity of type constructors will require a
different approach from System FC."

We will emphasize the limitations against FC better earlier in the 
paper, including discussions on erasability (which we have indeed 
not mentioned).  

- "The ideas in this paper are not new."

Our work essentially gives a positive answer to the question: 

"Can we have a calculus comparable in simplicity to PTS that can be 
used to model key features of modern functional languages (like Haskell
and ML), including general recursion, while preserving type-soundness 
and decidable type-checking?"

The suggestion from the reviewer that our work lacks novelty implies that 
it was already know (either directly or indirectly) that this question 
already had a positive answer. We disagree:

- None of the suggested references [1,2,3,4,5] gives a direct 
answer to this question. [1] does not support decidable type-checking; 
whereas [2,3,4,5] are significantly more complex than a PTS-based 
calculus. 

- We also disagree the ideas proposed by us are obvious from references 
[1,2,3,4,5]. 

The reviewer suggests that the idea of casts has already been proposed. 
While it is true that other systems have casts as an alternative to the 
conversion rule, including System FC which was our initial inspiration; 
the existing casts are fundamentally different. 

All cast approaches in [2,3,4,5] rely on an equality proof. Our one-step 
casts do not rely on equality proofs. This makes a big difference because: 

 1) To build equality proofs we need various other language constructs, which 
adds to the complexity of the language.

 2) More importantly, we need to ensure that the euqality proofs are valid. 
If we are not careful, in a language with non-termination, we could easily 
build equality proofs such as:

_|_ : Int = Char

Some of the languages do provide solutions to this problem. For example, 
in Zombie, the existence of a logical fragment can guarantee that the proofs 
are valid. Other approaches [3,4], include restricting valid equality proofs to be 
syntactic values only. 

Because our casts have no equality proofs, neither of these problems apply and 
thus the system can be much simpler. 




vs guru:

Guru has a cast construct using equality. However, this require more
language constructs that deal with equality, for example, we need
things like sim, reflexivity, transitivity …

Can Guru ensure that equality proofs are not bogus?

vs Trellys

Conversion rule uses equality proofs… like guru, but very
complicated. not single steps!

Avoiding bogus equality proofs: equality proofs have to be syntactic
values to ensure that they are logically consistent!

vs Trellys [3]

join n m <- lower and upper bounds for the number of steps to decide equality

- “The use of general recursion to implement recursive types is
already shown in Cardelli's paper”

Cardelli shows how to model *equi*-recursive types. He uses no casts,
and thus type-level computation is completely unrestricted. Therefore
there is no decidable type-checking in Cardelli’s system.  (similar to
Cayenne ??)

*The whole point* of our system is to provide a mechanism to control
type-level computation using inspiration from *iso*-recursive types. 
This is how we get decidable type-checking in
the presence of recursion at the type-level.  So there is clearly a
*big* difference to what Cardelli proposes.

* “Furthermore, the paper does not discuss the trade-offs involved when allowing
nontermination in dependently-typed languages.”

This is not correct. The issue of logical consistency is mentioned in
the introduction for example:

“… an additional concern, which does not exist in traditional
functional languages like Haskell, is how to ensure logical
consistency: that is ensuring the soundness of proofs written as
programs. Both λμ⋆ and System FC are logically inconsistent… In λμ⋆ ,
logical consistency is **traded** by the simplicity of the system.”

* “but this surface language lacks type-level computation, meaning that it
cannot take advantage of the main benefits of the core language.”

In fact the surface language takes very good advantage of the benefits
of the core language. The encoding of datatypes and case analysis, for
example, uses casts and type-level computation steps in a fundamental
way: we need to use casts to simulate fold/unfold, and we also need
small type-level computational steps to encode parametrised datatypes.

* Of course, in the presence of nontermination, this rule is
undecidable, but it can be made decidable by adding a maximum number of steps
that A and B should take to find the common term C.

Would not work:

%%% !!! WARNING: AUTO GENERATED. DO NOT MODIFY !!! %%%
%% ODER: format ==         = "\mathrel{==}"
%% ODER: format /=         = "\neq "
%
%
\makeatletter
\@ifundefined{lhs2tex.lhs2tex.sty.read}%
  {\@namedef{lhs2tex.lhs2tex.sty.read}{}%
   \newcommand\SkipToFmtEnd{}%
   \newcommand\EndFmtInput{}%
   \long\def\SkipToFmtEnd#1\EndFmtInput{}%
  }\SkipToFmtEnd

\newcommand\ReadOnlyOnce[1]{\@ifundefined{#1}{\@namedef{#1}{}}\SkipToFmtEnd}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{stmaryrd}
\DeclareFontFamily{OT1}{cmtex}{}
\DeclareFontShape{OT1}{cmtex}{m}{n}
  {<5><6><7><8>cmtex8
   <9>cmtex9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmtex10}{}
\DeclareFontShape{OT1}{cmtex}{m}{it}
  {<-> ssub * cmtt/m/it}{}
\newcommand{\texfamily}{\fontfamily{cmtex}\selectfont}
\DeclareFontShape{OT1}{cmtt}{bx}{n}
  {<5><6><7><8>cmtt8
   <9>cmbtt9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmbtt10}{}
\DeclareFontShape{OT1}{cmtex}{bx}{n}
  {<-> ssub * cmtt/bx/n}{}
\newcommand{\tex}[1]{\text{\texfamily#1}}	% NEU

\newcommand{\Sp}{\hskip.33334em\relax}


\newcommand{\Conid}[1]{\mathit{#1}}
\newcommand{\Varid}[1]{\mathit{#1}}
\newcommand{\anonymous}{\kern0.06em \vbox{\hrule\@width.5em}}
\newcommand{\plus}{\mathbin{+\!\!\!+}}
\newcommand{\bind}{\mathbin{>\!\!\!>\mkern-6.7mu=}}
\newcommand{\rbind}{\mathbin{=\mkern-6.7mu<\!\!\!<}}% suggested by Neil Mitchell
\newcommand{\sequ}{\mathbin{>\!\!\!>}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\usepackage{polytable}

%mathindent has to be defined
\@ifundefined{mathindent}%
  {\newdimen\mathindent\mathindent\leftmargini}%
  {}%

\def\resethooks{%
  \global\let\SaveRestoreHook\empty
  \global\let\ColumnHook\empty}
\newcommand*{\savecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\savecolumns[#1]}}
\newcommand*{\restorecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\restorecolumns[#1]}}
\newcommand*{\aligncolumn}[2]%
  {\g@addto@macro\ColumnHook{\column{#1}{#2}}}

\resethooks

\newcommand{\onelinecommentchars}{\quad-{}- }
\newcommand{\commentbeginchars}{\enskip\{-}
\newcommand{\commentendchars}{-\}\enskip}

\newcommand{\visiblecomments}{%
  \let\onelinecomment=\onelinecommentchars
  \let\commentbegin=\commentbeginchars
  \let\commentend=\commentendchars}

\newcommand{\invisiblecomments}{%
  \let\onelinecomment=\empty
  \let\commentbegin=\empty
  \let\commentend=\empty}

\visiblecomments

\newlength{\blanklineskip}
\setlength{\blanklineskip}{0.66084ex}

\newcommand{\hsindent}[1]{\quad}% default is fixed indentation
\let\hspre\empty
\let\hspost\empty
\newcommand{\NB}{\textbf{NB}}
\newcommand{\Todo}[1]{$\langle$\textbf{To do:}~#1$\rangle$}

\EndFmtInput
\makeatother
%
%
%
%
%
%
% This package provides two environments suitable to take the place
% of hscode, called "plainhscode" and "arrayhscode". 
%
% The plain environment surrounds each code block by vertical space,
% and it uses \abovedisplayskip and \belowdisplayskip to get spacing
% similar to formulas. Note that if these dimensions are changed,
% the spacing around displayed math formulas changes as well.
% All code is indented using \leftskip.
%
% Changed 19.08.2004 to reflect changes in colorcode. Should work with
% CodeGroup.sty.
%
\ReadOnlyOnce{polycode.fmt}%
\makeatletter

\newcommand{\hsnewpar}[1]%
  {{\parskip=0pt\parindent=0pt\par\vskip #1\noindent}}

% can be used, for instance, to redefine the code size, by setting the
% command to \small or something alike
\newcommand{\hscodestyle}{}

% The command \sethscode can be used to switch the code formatting
% behaviour by mapping the hscode environment in the subst directive
% to a new LaTeX environment.

\newcommand{\sethscode}[1]%
  {\expandafter\let\expandafter\hscode\csname #1\endcsname
   \expandafter\let\expandafter\endhscode\csname end#1\endcsname}

% "compatibility" mode restores the non-polycode.fmt layout.

\newenvironment{compathscode}%
  {\par\noindent
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \let\hspre\(\let\hspost\)%
   \pboxed}%
  {\endpboxed\)%
   \par\noindent
   \ignorespacesafterend}

\newcommand{\compaths}{\sethscode{compathscode}}

% "plain" mode is the proposed default.
% It should now work with \centering.
% This required some changes. The old version
% is still available for reference as oldplainhscode.

\newenvironment{plainhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\hspre\(\let\hspost\)%
   \pboxed}%
  {\endpboxed%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

\newenvironment{oldplainhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \(\pboxed}%
  {\endpboxed\)%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

% Here, we make plainhscode the default environment.

\newcommand{\plainhs}{\sethscode{plainhscode}}
\newcommand{\oldplainhs}{\sethscode{oldplainhscode}}
\plainhs

% The arrayhscode is like plain, but makes use of polytable's
% parray environment which disallows page breaks in code blocks.

\newenvironment{arrayhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \(\parray}%
  {\endparray\)%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

\newcommand{\arrayhs}{\sethscode{arrayhscode}}

% The mathhscode environment also makes use of polytable's parray 
% environment. It is supposed to be used only inside math mode 
% (I used it to typeset the type rules in my thesis).

\newenvironment{mathhscode}%
  {\parray}{\endparray}

\newcommand{\mathhs}{\sethscode{mathhscode}}

% texths is similar to mathhs, but works in text mode.

\newenvironment{texthscode}%
  {\(\parray}{\endparray\)}

\newcommand{\texths}{\sethscode{texthscode}}

% The framed environment places code in a framed box.

\def\codeframewidth{\arrayrulewidth}
\RequirePackage{calc}

\newenvironment{framedhscode}%
  {\parskip=\abovedisplayskip\par\noindent
   \hscodestyle
   \arrayrulewidth=\codeframewidth
   \tabular{@{}|p{\linewidth-2\arraycolsep-2\arrayrulewidth-2pt}|@{}}%
   \hline\framedhslinecorrect\\{-1.5ex}%
   \let\endoflinesave=\\
   \let\\=\@normalcr
   \(\pboxed}%
  {\endpboxed\)%
   \framedhslinecorrect\endoflinesave{.5ex}\hline
   \endtabular
   \parskip=\belowdisplayskip\par\noindent
   \ignorespacesafterend}

\newcommand{\framedhslinecorrect}[2]%
  {#1[#2]}

\newcommand{\framedhs}{\sethscode{framedhscode}}

% The inlinehscode environment is an experimental environment
% that can be used to typeset displayed code inline.

\newenvironment{inlinehscode}%
  {\(\def\column##1##2{}%
   \let\>\undefined\let\<\undefined\let\\\undefined
   \newcommand\>[1][]{}\newcommand\<[1][]{}\newcommand\\[1][]{}%
   \def\fromto##1##2##3{##3}%
   \def\nextline{}}{\) }%

\newcommand{\inlinehs}{\sethscode{inlinehscode}}

% The joincode environment is a separate environment that
% can be used to surround and thereby connect multiple code
% blocks.

\newenvironment{joincode}%
  {\let\orighscode=\hscode
   \let\origendhscode=\endhscode
   \def\endhscode{\def\hscode{\endgroup\def\@currenvir{hscode}\\}\begingroup}
   %\let\SaveRestoreHook=\empty
   %\let\ColumnHook=\empty
   %\let\resethooks=\empty
   \orighscode\def\hscode{\endgroup\def\@currenvir{hscode}}}%
  {\origendhscode
   \global\let\hscode=\orighscode
   \global\let\endhscode=\origendhscode}%

\makeatother
\EndFmtInput
%
%
%
% First, let's redefine the forall, and the dot.
%
%
% This is made in such a way that after a forall, the next
% dot will be printed as a period, otherwise the formatting
% of `comp_` is used. By redefining `comp_`, as suitable
% composition operator can be chosen. Similarly, period_
% is used for the period.
%
\ReadOnlyOnce{forall.fmt}%
\makeatletter

% The HaskellResetHook is a list to which things can
% be added that reset the Haskell state to the beginning.
% This is to recover from states where the hacked intelligence
% is not sufficient.

\let\HaskellResetHook\empty
\newcommand*{\AtHaskellReset}[1]{%
  \g@addto@macro\HaskellResetHook{#1}}
\newcommand*{\HaskellReset}{\HaskellResetHook}

\global\let\hsforallread\empty

\newcommand\hsforall{\global\let\hsdot=\hsperiodonce}
\newcommand*\hsperiodonce[2]{#2\global\let\hsdot=\hscompose}
\newcommand*\hscompose[2]{#1}

\AtHaskellReset{\global\let\hsdot=\hscompose}

% In the beginning, we should reset Haskell once.
\HaskellReset

\makeatother
\EndFmtInput

\section{Overview}

This section informally introduces the main features of \name. In
particular, this section shows how the explicit casts in \name can be
used instead of the typical conversion rule present in calculi such as
the calculus of constructions. The formal details of \name are
presented in Section~\ref{sec:ecore}.

\subsection{The Calculus of Constructions and the Conversion Rule}
\label{sec:coc}

The calculus of constructions (\coc)~\cite{coc} is a powerful
higher-order typed lambda calculus supporting dependent types (among
various other features).  A crutial
feature of \coc is the so-called \emph{conversion}
rule: \ottusedrule{\ottdruleTccXXConv{}}

%For the most part \name is similar to the \emph{Calculus of Constructions}
%(\coc)~\cite{coc}, which is a higher-order typed lambda calculus.
%However unlike \name and \coc is the
%absence of a conversion rule 

The conversion rule allows one to derive $e:\tau_{{\mathrm{2}}}$ from the
derivation of $e:\tau_{{\mathrm{1}}}$ and the $\beta$-equality of $\tau_{{\mathrm{1}}}$ and
$\tau_{{\mathrm{2}}}$. This rule is important to \emph{automatically} allow terms
with equivalent types to be considered type-compatible.  The following
example illustrates the use of the conversion rule:
\[
f \equiv \lambda  \ottmv{x}  \ottsym{:}  \ottsym{(}  \lambda  \ottmv{y}  \ottsym{:}  \star  \ottsym{.}  \ottmv{y}  \ottsym{)} \, \mathsf{Int}  \ottsym{.}  \ottmv{x}
\]
Here $f$ is a simple identity function. Notice that the type of $x$
(i.e., $\ottsym{(}  \lambda  \ottmv{y}  \ottsym{:}  \star  \ottsym{.}  \ottmv{y}  \ottsym{)} \, \mathsf{Int}$), which is the argument of $f$, is
interesting: it is an identity function on types, applied to an
integer.  Without the conversion rule, $f$ cannot be applied to, say
$3$ in \coc. However, given that $f$ is actually $\beta$-convertible
to $\lambda  \ottmv{x}  \ottsym{:}  \mathsf{Int}  \ottsym{.}  \ottmv{x}$, the conversion rule allows the application of $f$
to $3$ by implicitly converting $\lambda  \ottmv{x}  \ottsym{:}  \ottsym{(}  \lambda  \ottmv{y}  \ottsym{:}  \star  \ottsym{.}  \ottmv{y}  \ottsym{)} \, \mathsf{Int}  \ottsym{.}  \ottmv{x}$ to
$\lambda  \ottmv{x}  \ottsym{:}  \mathsf{Int}  \ottsym{.}  \ottmv{x}$.

\paragraph{Decidability of Type-Checking and Strong Normalization}
While the conversion rule in \coc brings a lot of convenience, an
unfortunate consequence is that it couples decidability of
type-checking with strong normalization of the
calculus~\cite{coc:decidability}.  However strong normalization does
not hold with general recursion. This is because due to the conversion
rule, any non-terminating term would force the type checker to go into
an infinitely loop (by constantly applying the conversion rule without
termination), thus rendering the type system undecidable.

To illustrate the problem of the conversion rule with general
recursion, let us consider a simple example. Suppose that
$d$ is a ``dependent type'' that has type $\mathsf{Int}  \rightarrow  \star$. With
general recursion at hand, we can image a term $z$ that has type
$d\,\mathsf{loop}$, where $\mathsf{loop}$ stands for any diverging
computation of type $ \mathsf{Int} $. What would happen if we try to type
check the following application: \[ \ottsym{(}  \lambda  \ottmv{x}  \ottsym{:}  \ottmv{d} \, 3  \ottsym{.}  \ottmv{x}  \ottsym{)} \, \ottmv{z}\]
Under the normal typing rules of \coc, the type checker would get
stuck as it tries to do $\beta$-equality on two terms: $d\,3$ and
$d\,\mathsf{loop}$, where the latter is non-terminating.  

\subsection{An Alternative to the Conversion Rule: Explicit Casts}

In contrast to the implicit
reduction rules of \coc, \name makes it explicit as to when and where
to convert one type to another. Type conversions are explicit by
introducing two language constructs: $ \mathsf{cast}_{\downarrow} $ (beta reduction)
and $ \mathsf{cast}^{\uparrow} $ (beta expansion). The benefit of this approach is
that decidability of type-checking no longer is coupled with strong
normalization of the calculus.

\paragraph{Beta Reduction} The first of the two type conversions
($ \mathsf{cast}_{\downarrow} $), allows a type conversion provided that the resulting
type is a \emph{beta reduction} of the original type of the term. The
use of $ \mathsf{cast}_{\downarrow} $ is better explained by the following simple
example. Assume a definition $g$:
\[ g \equiv \lambda  \ottmv{x}  \ottsym{:}  \mathsf{Int}  \ottsym{.}  \ottmv{x} \]
and term $z$ with type
\[ \ottsym{(}  \lambda  \ottmv{y}  \ottsym{:}  \star  \ottsym{.}  \ottmv{y}  \ottsym{)} \, \mathsf{Int} \]
In \name, and in constrast to the calculus of constructions,
$ g\,z $ is an ill-typed application. To type-check 
the application of $g$ to $z$ an explicit type conversion 
must be used:
\[ g\,(\mathsf{cast}_{\downarrow} \, \ottmv{z}) \]
In this case $ \mathsf{cast}_{\downarrow} $ is used because the program requires 
a (type-level) beta-reduction: 
$\ottsym{(}  \lambda  \ottmv{y}  \ottsym{:}  \star  \ottsym{.}  \ottmv{y}  \ottsym{)} \, \mathsf{Int} \rightarrow_{\beta}  \mathsf{Int} $. 

\paragraph{Beta Expansion} The dual operation of $ \mathsf{cast}_{\downarrow} $ is
$ \mathsf{cast}^{\uparrow} $, which allows a type conversion provided that the
resulting type is a \emph{beta expansion} of the original type of the
term.  Let us revisit the example from Section~\ref{sec:coc}. In \name,
$f\,3$ is an ill-typed application. Instead we must write the
application as
\[ f\,(\mathsf{cast}^{\uparrow} \, \ottsym{[}  \ottsym{(}  \lambda  \ottmv{y}  \ottsym{:}  \star  \ottsym{.}  \ottmv{y}  \ottsym{)} \, \mathsf{Int}  \ottsym{]} \,  3) \]
Intuitively,
$ \mathsf{cast}^{\uparrow} $ is doing a type conversion, as the type of $ 3 $ is
$  \mathsf{Int}  $, and $ \ottsym{(}  \lambda  \ottmv{y}  \ottsym{:}  \star  \ottsym{.}  \ottmv{y}  \ottsym{)} \, \mathsf{Int} $ is the beta expansion of
$ \mathsf{Int} $ (witnessed by
$\ottsym{(}  \lambda  \ottmv{y}  \ottsym{:}  \star  \ottsym{.}  \ottmv{y}  \ottsym{)} \, \mathsf{Int} \rightarrow_{\beta}  \mathsf{Int} $). Notice that for
$ \mathsf{cast}^{\uparrow} $ to work, we need to provide the resulting type as
argument. This is because for the same term, there are more than one
choices for beta expansions (e.g., $1 + 2$ and $2 + 1$ are both the
beta expansions of $3$). 

\paragraph{One-Step}
A final point to make is that the \cast rules specify \emph{one-step}
reductions/expansions. \bruno{show an example with two
  beta-reductions and show that two casts would be needed then.}
This enables us to have more control over type-level
computation. The full technical details about \cast rules are presented
in Section~\ref{sec:ecore}.

\subsection{Decidability without Strong Normalization}

With explicit type conversion rules the decidability of type-checking 
no longer depends on the normalization property. 
A nice consequence of this is that the type system remains decidable
even in the presence of non-terminating programs at type level.
%As we will see in later sections. The
%ability to write non-terminating terms motivates us to have more
%control over type-level computation. 
% To illustrate, let us consider the following example. Suppose that $d$ is a ``dependent type'' where
% \[d : \mathsf{Int}  \rightarrow  \star\] so that $d\,3$ or $d\,100$ all yield the same
% type. With general recursion at hand, we can image a term $z$ that has
% type \[d\,\mathsf{loop}\] where $\mathsf{loop}$ stands for any
% diverging computation and of type $ \mathsf{Int} $. What would happen if we
% try to type check the following application: \[ \ottsym{(}  \lambda  \ottmv{x}  \ottsym{:}  \ottmv{d} \, 3  \ottsym{.}  \ottmv{x}  \ottsym{)} \, \ottmv{z}\]
% Under the normal typing rules of \coc, the type checker would get
% stuck as it tries to do $\beta$-equality on two terms: $d\,3$ and
% $d\,\mathsf{loop}$, where the latter is non-terminating.

To illustrate, let us consider the same example discussed in
Section~\ref{sec:coc}. Now the type checker will not get stuck when
type-checking the following application:
\[ \ottsym{(}  \lambda  \ottmv{x}  \ottsym{:}  \ottmv{d} \, 3  \ottsym{.}  \ottmv{x}  \ottsym{)} \, \ottmv{z} \]
where the type of $z$ is $d\,\mathsf{loop}$.  This is because in
\name, the type checker only does syntactic comparison between $d\,3$
and $d\,\mathsf{loop}$, instead of $\beta$-equality. Therefore it
rejects the above application as ill-typed. Indeed it is impossible to
type-check the application even with the use of $ \mathsf{cast}^{\uparrow} $ and/or
$ \mathsf{cast}_{\downarrow} $: one would need to write infinite number of
$ \mathsf{cast}_{\downarrow} $'s to make the type checker loop forever (e.g.,
$(\lambda  \ottmv{x}  \ottsym{:}  \ottmv{d} \, 3  \ottsym{.}  \ottmv{x})( \mathsf{cast}_{\downarrow} ( \mathsf{cast}_{\downarrow}  \dots z))$). But it is
impossible to write such program in reality.

In summary, \name achieves the decidability of type checking by
explicitly controlling type-level computation.  which is independent
of the normalization property, while supporting general recursion at
the same time.

\subsection{Recursion and Recursive Types}

\name supports general recursion, and allows writing standard
recursive programs at the term level. At the same time, the recursive
construct can also be used to model recursive types at the type-level.
Therefore, \name differs from other programming languages in that it
\emph{unifies} both recursion and recursive types by the same $\mu$
primitive. With a single language construct we get two powerful
features!

\paragraph{Recursion}

The $\mu$ primitive can be used to define recursive functions.  For
example, the factorial function is written in \name as:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{fact}\mathrel{=}\mu\;\Varid{f}\mathbin{:}\Conid{Int}\to \Conid{Int}.\,\mathbf{if}\;\Varid{x}==\mathrm{0}\;\mathbf{then}\;\mathrm{1}\;\mathbf{else}\;\Varid{x}\;\times\;\Varid{f}\;(\Varid{x}\mathbin{-}\mathrm{1}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\bruno{x is not bound!}\bruno{show how to use fact}
The above recursive definition works because of the dynamic semantics of the
$\mu$ primitive: \ottusedrule{\ottdruleSXXMu{}} which is exactly doing
recursive unfolding of itself.

It is worth noting that the type $\tau$ in \ruleref{S\_Mu} is not
restricted to function types. This extra freedom allows us to define a
record of mutually recursive functions as the fixed point of a
function on records.

% The dynamic semantics of $\mu$ requires the recursive binder to satisfy (omit type annotations for clarity):  \[ \mu f.\,E = (\lambda f.\,E) (\mu f.\,E) \] which, however, does not terminate in strict languages. Therefore, to loosen the function-type restriction to allow any types, the sensible choice for the evaluation strategy is \emph{call-by-name}.

\subsubsection{Recursive types}
In the literature on type systems, there are two approaches to
recursive types, namely \emph{equi-recursive} and
\emph{iso-recursive}\bruno{reference}. The \emph{iso-recursive} approach treats a
recursive type and its unfolding as different, but isomorphic. The
isomorphism between a recursive type and its one step unfolding is
witnessed by \fold and \unfold operations. In \name, the
isomorphism is witnessed by first $ \mathsf{cast}^{\uparrow} $, then
$ \mathsf{cast}_{\downarrow} $. In fact, $ \mathsf{cast}^{\uparrow} $ and
$ \mathsf{cast}_{\downarrow} $ actually generalize \fold and \unfold: they can convert
any types, not just recursive types. 

To demonstrate the use of the
\cast rules with recursive types, let us consider a classic example of a recursive type,
the so-called ``hungry'' type~\cite{tapl}:
\[H = \miu{\sigma}{\star}{\mathsf{Int} \rightarrow \sigma}\]
A term $z$
of type $H$ can accept any number of integers and return a new
function that is hungry for more, as illustrated below:
\begin{align*}
\mathsf{cast}_{\downarrow} \, \ottmv{z} &:  \mathsf{Int}  \rightarrow H  \\
\mathsf{cast}_{\downarrow} \, \ottsym{(}  \mathsf{cast}_{\downarrow} \, \ottmv{z}  \ottsym{)} &:  \mathsf{Int}  \rightarrow  \mathsf{Int}  \rightarrow H \\
 \mathsf{cast}_{\downarrow} ( \mathsf{cast}_{\downarrow}  \dots z) &:  \mathsf{Int}  \rightarrow  \mathsf{Int}  \rightarrow \dots \rightarrow H
\end{align*}

% Due to the unification of recursive types and recursion, we can use
% the same $\mu$ primitive to write both recursive types and recursion
% with ease.

\paragraph{Call-by-Name}
Due to the unification, the \emph{call-by-value} evaluation strategy
does not fit in our setting. In call-by-value evaluation, recursion
can be expressed by the recursive binder $\mu$ as $\mu f : T
\rightarrow T.\, E$ (note that the type of $f$ is restricted to
function types). Since we don't want to pose restrictions on the
types, the \emph{call-by-name} evaluation is a sensible choice.
\bruno{Probably needs to be improved. I'll came back to this later!}

\subsection{Logical Inconsistency}
Although the decidability of type-checking is preserved, a consequence
having general recursion in \name is that the logical consistency is
lost. In \name every type is inhabited, which is problematic if we
want to view \name as a logic. Indeed, unlike many other dependently 
calculi which have been proposed in the past, \name cannot be used 
directly to do theorem proving.

Nevertheless the loss of logical consistency is a deliberate design
decision. Although there are dependently typed languages that support
general recursion and still preserve logical consistency, this is done
at the cost of additional complexity in the
system~\cite{}\bruno{references}.  In \name we trade the loss of
logical consistency by a significantly simpler system.

Since our goal is 
use \name as a foundational calculus for languages like Haskell,
logical consistency is not an important property: traditional 
functional languages like Haskell are logically inconsistent as well. 
For example, in Haskell, we can write a ``false'' type:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{type}\;\Conid{False}\mathrel{=}\forall \Varid{a}\hsforall .\,\Varid{a}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
With general recursion, a value with type \ensuremath{\Conid{False}} is given:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{false}\mathbin{::}\Conid{False}{}\<[E]%
\\
\>[3]{}\Varid{false}\mathrel{=}\Varid{false}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
whose denotational semantics is \ensuremath{\bot }, which corresponds to
inconsistency in logic. 

\paragraph{Type in Type}
Since logical consistency is already lost due to general recursion, 
\name also uses the $\star : \star$ axiom\bruno{reference?}. 
As a consequence, having this rule adds expressiveness and
simplifies our system (e.g., it will be easy to explicitly quantify
over kinds). We return to this issue in Section~\ref{sec:related}.

\subsection{Encoding Datatypes}

The explicit type conversion rules and the $\mu$ primitive facilitates
the encoding of recursive datatypes and recursive functions over
datatypes. While inductive datatypes can be encoded using either the
Church~\cite{tapl} or the Scott encoding~\cite{encoding:scott}, we
adopt the Scott encoding as it encodes case analysis, making it more
convenient to encode pattern matching. We demonstrate the encoding
method using a simple datatype as a running example: Peano numbers.

The datatype declaration for Peano numbers in Haskell is:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[4]{}\mathbf{data}\;\Conid{Nat}\mathrel{=}\Conid{Z}\mid \Conid{S}\;\Conid{Nat}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
In the Scott encoding, the encoding of the \emph{Nat} datatype
reflects how its two constructors are going to be used. Since
\emph{Nat} is a recursive datatype, we have to use recursive types at
some point to reflect its recursive nature. As it turns out, the typed
Scott encoding of \emph{Nat} is:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mu\;\Conid{X}\mathbin{:}\star.\,\Pi\;\Conid{B}\mathbin{:}\star.\,\Conid{B}\to (\Conid{X}\to \Conid{B})\to \Conid{B}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
The function type \ensuremath{\Conid{B}\to (\Conid{X}\to \Conid{B})\to \Conid{B}} demystifies the recursive
nature of \emph{Nat}: $B$ corresponds to the type of the constructor
\emph{Z}, and \ensuremath{\Conid{X}\to \Conid{B}} corresponds to the type of the constructor
\emph{S}. The intuition is that any recursive use of the datatype in
the data constructors is replaced with the variable ($X$ in the case)
bound by $\mu$, and we make the resulting variable ($B$ in this case)
universally quantified so that elements of the datatype with different
result types can be used in the same program~\cite{gadts}.

The two constructors can be encoded correspondingly via the \cast rules:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Conid{Z}\mathrel{=}\mathsf{cast}^\uparrow\;[\mskip1.5mu \Conid{Nat}\mskip1.5mu]\;(\lambda \Conid{B}\mathbin{:}\star.\,\lambda \Varid{z}\mathbin{:}\Conid{B}.\,\lambda \Varid{f}\mathbin{:}\Conid{Nat}\to \Conid{B}.\,\Varid{z}){}\<[E]%
\\
\>[3]{}\Conid{S}\mathrel{=}\lambda \Varid{n}\mathbin{:}\Conid{Nat}.\,\mathsf{cast}^\uparrow\;[\mskip1.5mu \Conid{Nat}\mskip1.5mu]\;(\lambda \Conid{B}\mathbin{:}\star.\,\lambda \Varid{z}\mathbin{:}\Conid{B}.\,\lambda \Varid{f}\mathbin{:}\Conid{Nat}\to \Conid{B}.\,\Varid{f}\;\Varid{n}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\bruno{be careful with code overflowing margins! Maybe use 2 lines?}
Intuitively, each constructor selects a different function from the
function parameters ($z$ and $f$ in the above example). This provides
branching in the process flow, based on the constructors. Note that we
use the $ \mathsf{cast}^{\uparrow} $ operation to do type conversion between the
recursive type and its unfolding.

Finally a recursive function that adds two natural numbers is defined
as follows:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mu\;\Varid{f}\mathbin{:}\Conid{Nat}\to \Conid{Nat}\to \Conid{Nat}.\,\lambda \Varid{n}\mathbin{:}\Conid{Nat}.\,\lambda \Varid{m}\mathbin{:}\Conid{Nat}.\,{}\<[E]%
\\
\>[3]{}\hsindent{4}{}\<[7]%
\>[7]{}(\mathsf{cast}_\downarrow\;\Varid{n})\;\Conid{Nat}\;\Varid{m}\;(\lambda \Varid{n'}\mathbin{:}\Conid{Nat}.\,\Conid{S}\;(\Varid{f}\;\Varid{n'}\;\Varid{m})){}\<[E]%
\ColumnHook
\end{hscode}\resethooks
The above definition resembles case analysis commonly seen in
modern functional programming languages.\bruno{Explain the use of cast}
Indeed, we will formalize an encoding of 
case analysis in Section~\ref{sec:surface}.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:

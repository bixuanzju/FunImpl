%%% !!! WARNING: AUTO GENERATED. DO NOT MODIFY !!! %%%
%% ODER: format ==         = "\mathrel{==}"
%% ODER: format /=         = "\neq "
%
%
\makeatletter
\@ifundefined{lhs2tex.lhs2tex.sty.read}%
  {\@namedef{lhs2tex.lhs2tex.sty.read}{}%
   \newcommand\SkipToFmtEnd{}%
   \newcommand\EndFmtInput{}%
   \long\def\SkipToFmtEnd#1\EndFmtInput{}%
  }\SkipToFmtEnd

\newcommand\ReadOnlyOnce[1]{\@ifundefined{#1}{\@namedef{#1}{}}\SkipToFmtEnd}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{stmaryrd}
\DeclareFontFamily{OT1}{cmtex}{}
\DeclareFontShape{OT1}{cmtex}{m}{n}
  {<5><6><7><8>cmtex8
   <9>cmtex9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmtex10}{}
\DeclareFontShape{OT1}{cmtex}{m}{it}
  {<-> ssub * cmtt/m/it}{}
\newcommand{\texfamily}{\fontfamily{cmtex}\selectfont}
\DeclareFontShape{OT1}{cmtt}{bx}{n}
  {<5><6><7><8>cmtt8
   <9>cmbtt9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmbtt10}{}
\DeclareFontShape{OT1}{cmtex}{bx}{n}
  {<-> ssub * cmtt/bx/n}{}
\newcommand{\tex}[1]{\text{\texfamily#1}}	% NEU

\newcommand{\Sp}{\hskip.33334em\relax}


\newcommand{\Conid}[1]{\mathit{#1}}
\newcommand{\Varid}[1]{\mathit{#1}}
\newcommand{\anonymous}{\kern0.06em \vbox{\hrule\@width.5em}}
\newcommand{\plus}{\mathbin{+\!\!\!+}}
\newcommand{\bind}{\mathbin{>\!\!\!>\mkern-6.7mu=}}
\newcommand{\rbind}{\mathbin{=\mkern-6.7mu<\!\!\!<}}% suggested by Neil Mitchell
\newcommand{\sequ}{\mathbin{>\!\!\!>}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\usepackage{polytable}

%mathindent has to be defined
\@ifundefined{mathindent}%
  {\newdimen\mathindent\mathindent\leftmargini}%
  {}%

\def\resethooks{%
  \global\let\SaveRestoreHook\empty
  \global\let\ColumnHook\empty}
\newcommand*{\savecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\savecolumns[#1]}}
\newcommand*{\restorecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\restorecolumns[#1]}}
\newcommand*{\aligncolumn}[2]%
  {\g@addto@macro\ColumnHook{\column{#1}{#2}}}

\resethooks

\newcommand{\onelinecommentchars}{\quad-{}- }
\newcommand{\commentbeginchars}{\enskip\{-}
\newcommand{\commentendchars}{-\}\enskip}

\newcommand{\visiblecomments}{%
  \let\onelinecomment=\onelinecommentchars
  \let\commentbegin=\commentbeginchars
  \let\commentend=\commentendchars}

\newcommand{\invisiblecomments}{%
  \let\onelinecomment=\empty
  \let\commentbegin=\empty
  \let\commentend=\empty}

\visiblecomments

\newlength{\blanklineskip}
\setlength{\blanklineskip}{0.66084ex}

\newcommand{\hsindent}[1]{\quad}% default is fixed indentation
\let\hspre\empty
\let\hspost\empty
\newcommand{\NB}{\textbf{NB}}
\newcommand{\Todo}[1]{$\langle$\textbf{To do:}~#1$\rangle$}

\EndFmtInput
\makeatother
%

\section{Overview}

\bruno{Jeremy: can you give this section a go and start writing it up? I think this section should be your priority for now.}

We begin this section with an informal introduction to the main features of \name. We show how it can serve as a simple and compiler-friendly core language with general recursion and decidable type system. The formal details are presented in \S\ref{sec:formal}.

\subsection{Calculus of Constructions}
\label{sec:coc}

\name is based on the \emph{Calculus of Constructions} (\coc)~\cite{coc}, which is a higher-order typed lambda calculus. One ``unconventional'' feature of \coc is the so-called \emph{conversion} rule as shown below:
\ottusedrule{\ottdruleTccXXConv{}}

The conversion rule allows one to derive $e:\tau_{{\mathrm{2}}}$ from the derivation of $e:\tau_{{\mathrm{1}}}$ and the $\beta$-equality of $\tau_{{\mathrm{1}}}$ and $\tau_{{\mathrm{2}}}$. Note that in \coc, the use of this rule is implicit in that it is automatically applied during type checking to all non-normal form terms. To illustrate, let us consider a simple example. Suppose we have a built-in base type $ \kw{Int} $ and \[f \equiv \lambda  \ottmv{x}  \ottsym{:}  \ottsym{(}  \lambda  \ottmv{y}  \ottsym{:}  \star  \ottsym{.}  \ottmv{y}  \ottsym{)} \, \kw{Int}  \ottsym{.}  \ottmv{x} \] Without the conversion rule, $f$ cannot be applied to, say $3$ in \coc. Given that $f$ is actually $\beta$-convertible to $\lambda  \ottmv{x}  \ottsym{:}  \kw{Int}  \ottsym{.}  \ottmv{x}$, the conversion rule would allow the application of $f$ to $3$ by implicitly converting $\lambda  \ottmv{x}  \ottsym{:}  \ottsym{(}  \lambda  \ottmv{y}  \ottsym{:}  \star  \ottsym{.}  \ottmv{y}  \ottsym{)} \, \kw{Int}  \ottsym{.}  \ottmv{x}$ to $\lambda  \ottmv{x}  \ottsym{:}  \kw{Int}  \ottsym{.}  \ottmv{x}$.

\subsection{Explicit Type Conversion Rules}

\bruno{Contrast our calculus with the calculus of constructions. Explain fold/unfold.}

In contrast to the implicit reduction rules of \coc, \name makes it explicit as to when and where to convert one type to another. To achieve that, it makes type conversion explicit by introducing two operations: $ \kw{cast}^{\uparrow} $ and $ \kw{cast}_{\downarrow} $.

In order to have a better intuition, let us consider the same example from \S\ref{sec:coc}. In \name, $f\,3$ is intended as an ill-typed application. Instead one would like to write the application as \[ f\,(\kw{cast}^{\uparrow} \, \ottsym{[}  \ottsym{(}  \lambda  \ottmv{y}  \ottsym{:}  \star  \ottsym{.}  \ottmv{y}  \ottsym{)} \, \kw{Int}  \ottsym{]}  3) \] The intuition is that, $ \kw{cast}^{\uparrow} $ is actually doing type conversion since the type of $ 3 $ is $  \kw{Int}  $ and $ \ottsym{(}  \lambda  \ottmv{y}  \ottsym{:}  \star  \ottsym{.}  \ottmv{y}  \ottsym{)} \, \kw{Int} $ can be reduced to $  \kw{Int}  $.

The dual operation of $ \kw{cast}^{\uparrow} $ is $ \kw{cast}_{\downarrow} $. The use of $ \kw{cast}_{\downarrow} $ is better explained by another similar example. Suppose that \[ g \equiv \lambda  \ottmv{x}  \ottsym{:}  \kw{Int}  \ottsym{.}  \ottmv{x} \] and term $z$ has type \[ \ottsym{(}  \lambda  \ottmv{y}  \ottsym{:}  \star  \ottsym{.}  \ottmv{y}  \ottsym{)} \, \kw{Int} \] $ g\,z $ is again an ill-typed application, while $ g\,(\kw{cast}_{\downarrow} \, \ottmv{z}) $ is type correct because $ \kw{cast}_{\downarrow} $ reduces the type of $ z $ to $  \kw{Int}  $.

\subsection{Decidability and Strong Normalization}

\bruno{Informally explain that with explicit fold/unfold rules the decidability of the
type system does not depend on strong normalization.}

The decidability of the type system of \coc depends on the normalization property for all constructed terms~\cite{coc:decidability}. However strong normalization does not hold with general recursion. This is simply because due to the conversion rule, any non-terminating term would force the type checker to go into an infinitely loop (by constantly applying the conversion rule without termination), thus rendering the type system undecidable.

With explicit type conversion rules, however, the decidability of the type system no longer depends on the normalization property. In fact \name is not strong normalizing, as we will see in later sections. The ability to write non-terminating terms motivates us to have more control over type-level computation. To illustrate, let us consider a contrived example. Suppose that $d$ is a ``dependent type'' where \[d : \kw{Int}  \rightarrow  \star\] so that $d\,3$ or $d\,100$ all yield the same type.  With general recursion at hand, we can image  a term $z$ that has type \[d\,\mathsf{loop}\] where $\mathsf{loop}$ stands for any diverging computation and of type $ \kw{Int} $. What would happen if we try to type check the following application: \[ \ottsym{(}  \lambda  \ottmv{x}  \ottsym{:}  \ottmv{d} \, 3  \ottsym{.}  \ottmv{x}  \ottsym{)} \, \ottmv{z}\] Under the normal typing rules of \coc, the type checker would get stuck as it tries to do $\beta$-equality on two terms: $d\,3$ and $d\,\mathsf{loop}$, where the latter is non-terminating.

This is not the case for \name: (i) it has no such conversion rule, therefore the type checker would do syntactic comparison between the two terms instead of $\beta$-equality in the above example; and (ii) one would need to write infinite number of $ \kw{cast}_{\downarrow} $'s to make the type checker loop forever (e.g., $(\lambda  \ottmv{x}  \ottsym{:}  \ottmv{d} \, 3  \ottsym{.}  \ottmv{x})( \kw{cast}_{\downarrow} ( \kw{cast}_{\downarrow}  \dots z) $), which is impossible in reality.

In summary, \name achieves the decidability of type checking by explicitly controlling type-level computation, which is independent of the normalization property, while supporting general recursion at the same time.

\subsection{Unifying Recursive Types and Recursion}

\bruno{Show how in \name recursion and recursive types are unified.
Discuss that due to this unification the sensible choice for the
evaluation strategy is call-by-name. }

Recursive types arise naturally if we want to do general recursion. \name differs from other programming languages in that it unifies both recursion and recursive types by the same $\mu$ primitive.

\emph{Recursive types}. In the literature on type systems, there are two approaches to recursive types. One is called \emph{equi-recursive}, the other \emph{iso-recursive}. \name takes the latter approach since it is more intuitive to us with regard to recursion. The \emph{iso-recusive} approach treats a recursive type and its unfolding as different, but isomorphic. In \name, this is witnessed by first $ \kw{cast}^{\uparrow} $, then $ \kw{cast}_{\downarrow} $. A classic example of recursive types is the so-called ``hungry'' type: $H = \miu{\sigma}{\star}{\mathsf{Int} \rightarrow \sigma}$. A term $z$ of type $H$ can accept any number of numeric arguments and return a new function that is hungry for more, as illustrated below:
\begin{align*}
\kw{cast}_{\downarrow} \, \ottmv{z} &:  \kw{Int}  \rightarrow H  \\
\kw{cast}_{\downarrow} \, \ottsym{(}  \kw{cast}_{\downarrow} \, \ottmv{z}  \ottsym{)} &:  \kw{Int}  \rightarrow  \kw{Int}  \rightarrow H \\
 \kw{cast}_{\downarrow} ( \kw{cast}_{\downarrow}  \dots z) &:  \kw{Int}  \rightarrow  \kw{Int}  \rightarrow \dots \rightarrow H
\end{align*}

\emph{Recursion}. The same $\mu$ primitive can also be used to define recursive functions, e.g., the factorial function: \[\miu{f}{\mathsf{Int} \rightarrow \mathsf{Int}}{\lam{x}{\mathsf{Int}}{\mathsf{if}\,(x == 0)\,\mathsf{then}\,1\,\mathsf{else}\,x * f\,(x - 1)}}\] This is reflected by the dynamic semantics of the $\mu$ primitive:
\[\miu{x}{T}{E} \longrightarrow E[x:=\miu{x}{T}{E}]\]
which is exactly doing recursive unfolding of the same term.

Due to the unification, the \emph{call-by-value} evaluation strategy does not fit in our setting. In call-by-value evaluation, recursion can be expressed by the recursive binder $\mu$ as $\mu f : T \rightarrow T.\, E$ (note that the type of $f$ is restricted to function types). Since we don't want to pose restrictions on the types, the \emph{call-by-name}  evaluation is a sensible choice.

% The dynamic semantics of $\mu$ requires the recursive binder to satisfy (omit type annotations for clarity):  \[ \mu f.\,E = (\lambda f.\,E) (\mu f.\,E) \] which, however, does not terminate in strict languages. Therefore, to loosen the function-type restriction to allow any types, the sensible choice for the evaluation strategy is \emph{call-by-name}.

\subsection{Encoding Datatypes}

\bruno{Informally explain how to encode recursive datatypes and recursive functions
using datatypes.}


With the explicit type conversion rules and the $\mu$ primitive, it is straightforward to encode recursive datatypes and recusive functions using datatypes. While inductive datatypes can be encoded using either the Church or the Scott encoding, we adopt the Scott encoding as it is bear some resemblance to case analysis, making it more convenient to encode pattern matching. We demonstrate the encoding method using a simple datatype as a running example: the natural numbers.

The datatype declaration for natural numbers is:
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{data}\;\Conid{Nat}\mathrel{=}\Conid{Z}\mid \Conid{S}\;\Conid{Nat};{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks

In the Scoot encoding, the encoding of the \emph{Nat} type reflects how its two constructors are going to be used. Since \emph{Nat} is a recursive datatype, we have to use recursive types at some point to reflect its recursive nature. As it turns out, the \emph{Nat} type can be simply represented as \ensuremath{\mu\;\Conid{X}\mathbin{:}\star.\,\Pi\;\Conid{B}\mathbin{:}\star.\,\Conid{B}\to (\Conid{X}\to \Conid{B})\to \Conid{B}}.

As can be seen, in the function type \ensuremath{\Conid{B}\to (\Conid{X}\to \Conid{B})\to \Conid{B}}, $B$ corresponds to the type of the \emph{Z} constructor, and \ensuremath{\Conid{X}\to \Conid{B}} corresponds to the type of the \emph{S} constructor. The intuition is that any use of the datatype being defined in the constructors is replaced with the recursive type, except for the return type, which is a type variable for use in the recursive functions.

Now its two constructors can be encoded correspondingly as below:

\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Conid{Z}\mathbin{:}\Conid{Nat}\mathrel{=}\mathsf{cast}^\uparrow\;[\mskip1.5mu \Conid{Nat}\mskip1.5mu]\;(\lambda \Conid{B}\mathbin{:}\star.\,\lambda \Varid{z}\mathbin{:}\Conid{B}.\,\lambda \Varid{f}\mathbin{:}\Conid{Nat}\to \Conid{B}.\,\Varid{z}){}\<[E]%
\\
\>[3]{}\mathbf{in}{}\<[E]%
\\
\>[3]{}\mathbf{let}\;\Conid{S}\mathbin{:}\Conid{Nat}\to \Conid{Nat}\mathrel{=}\lambda \Varid{n}\mathbin{:}\Conid{Nat}.\,{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\mathsf{cast}^\uparrow\;[\mskip1.5mu \Conid{Nat}\mskip1.5mu]\;(\lambda \Conid{B}\mathbin{:}\star.\,\lambda \Varid{z}\mathbin{:}\Conid{B}.\,\lambda \Varid{f}\mathbin{:}\Conid{Nat}\to \Conid{B}.\,\Varid{f}\;\Varid{n}){}\<[E]%
\\
\>[3]{}\mathbf{in}{}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks

% \begin{align*}
%   \letbb\,&\zero : \Nat = \fold{\Nat}{(\lambda (b : \star) (z : b) (f : \Nat \rightarrow b).\,z)}\,\inb \\
%   \letbb\,&\suc : \Nat \rightarrow \Nat = \lambda (n : \Nat).\,\fold{\Nat}{(\lambda (b : \star) (z : b)\\ &(f : \Nat \rightarrow b).\,f\,n)}\,\inb
% \end{align*}
Thanks to the explicit type conversion rules, we can make use of the $ \kw{cast}^{\uparrow} $ operation to do type conversion between the recursive type and its unfolding.

As the last example, let us see how we can define recursive functions using the \emph{Nat} datatype. A simple example would be recursively adding two natural numbers, which can be defined as below:
\begingroup\par\noindent\advance\leftskip\mathindent\(
\begin{pboxed}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\mathbf{let}\;\Varid{add}\mathbin{:}\Conid{Nat}\to \Conid{Nat}\to \Conid{Nat}\mathrel{=}\mu\;\Varid{f}\mathbin{:}\Conid{Nat}\to \Conid{Nat}\to \Conid{Nat}.\,{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\lambda \Varid{n}\mathbin{:}\Conid{Nat}.\,\lambda \Varid{m}\mathbin{:}\Conid{Nat}.\,{}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}(\mathsf{cast}_\downarrow\;\Varid{n})\;\Conid{Nat}\;\Varid{m}\;(\lambda \Varid{n'}\mathbin{:}\Conid{Nat}.\,\Conid{S}\;(\Varid{f}\;\Varid{n'}\;\Varid{m})){}\<[E]%
\ColumnHook
\end{pboxed}
\)\par\noindent\endgroup\resethooks
% \begin{align*}
%   \mu f &: \Nat \rightarrow \Nat \rightarrow \Nat.\,\lambda n : \Nat.\,\lambda m : \Nat.\\
%   &(\unfold{n})\,\Nat\,m\,(\lam{n'}{\Nat}{\suc\,(f\,n'\,m)})
% \end{align*}
As we can see, the above definition quite resembles case analysis common in modern functional programming languages. (Actually we formalize the encoding of case analysis in \S\ref{sec:surface}.)

Due to the unification of recursive types and recursion, we can use the same $\mu$ primitive to write both recursive types and recursion with ease.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:

<<<<<<< HEAD
\section{A Dependently Typed Calculus with Casts}\label{sec:ecore}
=======
\section{The Core Language without Recursion}\label{sec:ecore}
>>>>>>> fbb4aec38d0781583a5ed947f0c14728f5c1f918

In this section, we present \ecore calculus. \ecore is a subset of the core
language \name without general recursion. By explicitly controlling the type-level
computation with \cast operators, \ecore has decidable type-checking
without requiring strong normalization. In rest of this
section, we demonstrate the syntax, operational semantics, typing
rules and meta-theory of \ecore.

\subsection{Syntax}\label{sec:ecore:syn}
Figure \ref{fig:ecore:syntax} shows the syntax of \ecore, including
expressions, contexts and values. The syntax follows closely the
calculus of constructions (\cc). Two important differences, however, are: 1)
the absence of the $\Box$ constant (due to use of the "type-in-type"
axiom); 2) the existence of two \cast operators.

\subsubsection{Unified syntactic levels}
\ecore uses a unified syntactic representation for different levels of
expressions by following the \emph{pure type system} (PTS)
representation of \cc. Traditionally in \cc, there are two distinct
sorts $[[star]]$ and $[[square]]$ representing the type of
\emph{types} and \emph{sorts} respectively, and an axiom
$[[star]]:[[square]]$ specifying the relation. In \ecore, we further
merge types and kinds together by including only a single sort
$[[star]]$ and an impredicative axiom $[[star]]:[[star]]$. 

Therefore, there is no syntactic distinction between terms, types or
kinds. This design brings the economy for type checking, since one set
of rules can cover all syntactic levels. By convention, we use
metavariables $[[t]]$ and $[[T]]$ for an expression on the type-level
position and $e$ for one on the term level.

\subsubsection{Dependent function types}
In the context of \cc, if a term $[[x]]$ has the type $[[t1]]$, and $[[t2]]$ is a type, i.e. $[[x]]:[[t1]]:[[star]]$ and $[[t2]]:[[square]]$, we call the type $[[Pi x:t1.t2]]$ a \emph{dependent product}. \ecore follows \cc to use the same $[[Pi]]$-notation to represent dependent function types.

However, a higher-kind polymorphic function type such as $[[Pi x:square.x->x]]$ is not allowed in \cc, because $[[square]]$ is the highest sort that can not be typed. While $[[Pi]]$-notation in \ecore is more expressive and does not have such limitation because of the axiom $[[star]]:[[star]]$. In the source language, we interchangeably use the arrow form $[[(x:t1)->t2]]$ of the product for clarity. By convention, we also use the syntactic sugar $[[t1 --> t2]]$ to represent the product if $[[x]]$ does not occur free in $[[t2]]$.

\subsubsection{Explicit type conversion}
We introduce two new primitives $[[castup]]$ and $[[castdown]]$ (pronounced as "cast up" and "cast down") to replace implicit conversion rule of \cc with \emph{one-step} explicit type conversion. They represent two directions of type conversion: $[[castdown]]$ stands for the $\beta$-reduction of types, while $[[castup]]$ is the inverse \fixme{(see examples in \S \ref{sec:})}.

Though \cast primitives make the syntax verbose when type conversion is heavily used, the implementation of type checking is simplified because typing rules of \ecore become type-directed without \cc's implicit conversion rule. Considering the core language is compiler-oriented and \fixme{source language does not include \cast primitives}, end-users will not directly use them. Some type conversions can be generated through the translation of the source language \fixme{(\S \ref{sec:src})}.

\begin{figure}
    \gram{\ottec\ottinterrule
        \ottG\ottinterrule
        \ottv}
    \caption{Syntax of \ecore}
    \label{fig:ecore:syntax}
\end{figure}

\subsection{Operational Semantics}\label{sec:ecore:opsem}
Figure \ref{fig:ecore:opsem} shows the \emph{call-by-name} operational semantics, defined by one-step reduction. Two base cases include \ruleref{S\_Beta} for $\beta$-reduction and \ruleref{S\_CastDownUp} for cast canceling. Two inductive case, \ruleref{S\_App} and \ruleref{S\_CastDown}, define reduction in the head position of an application, and in the $[[castdown]]$ inner expression respectively. The reduction rules are \emph{weak} in the sense that it is not allowed to reduce inside a $\lambda$-term or $[[castup]]$-term which is viewed as a value (see Figure \ref{fig:ecore:syntax}).

To evaluate the value of a term-level expression, we apply the one-step reduction multiple times. The number of evaluation steps is not restricted, which is possible to be infinite. The multi-step reduction can be defined as follows:
\begin{dfn}[Multi-step reduction]
    The relation $[[->>]]$ is the transitive and reflexive closure of the one-step reduction $[[-->]]$.
\end{dfn}

But for a type-level expression, the evaluation is driven by \cast operators, which is finite. For a consecutive sequence of reductions with $n$ steps, we use the notation $[[-->>]]$ to denote the relation between the initial and final expressions:
\begin{dfn}[$n$-step reduction]
    The $n$-step reduction is denoted by $[[e0]] [[-->>]] [[en]]$, if there exists a sequence of one-step reductions $[[e0]] [[-->]] [[e1]] [[-->]] [[e2]] [[-->]] \dots [[-->]] [[en]]$, where $n$ is a positive integer and $[[ei]]\,(i=0,1,\dots,n)$ are valid expressions.
\end{dfn}

\begin{figure}
    \ottdefnstep{}
    \caption{Operational semantics of \ecore}
    \label{fig:ecore:opsem}
\end{figure}

\subsection{Typing}\label{sec:ecore:type}
Figure \ref{fig:ecore:typing} gives the \emph{syntax-directed} typing rules of \ecore, including rules of context well-formedness $[[|- G]]$ and expression typing $[[G |- e : t]]$. Note that there is only a single set of rules for expression typing, because there is no distinction of different syntactic levels.

Most typing rules are quite standard. We write $[[|- G]]$ if a context $[[G]]$ is well-formed. Note that there is only a single sort $[[star]]$, we use $[[G |- t : star]]$ to check if $[[t]]$ is a well-formed type. Rule \ruleref{T\_Ax} is the "type-in-type" axiom. Rule \ruleref{T\_Var} checks the type of variable $[[x]]$ from the valid context. Rules \ruleref{T\_App} and \ruleref{T\_Lam} check the validity of application and abstraction. Rules \ruleref{T\_Pi} check the type well-formedness of the dependent function.

We focus on rules \ruleref{T\_CastUp} and \ruleref{T\_CastDown} that define the semantics of \cast operators and replace the conversion rule of \cc~\fixme{(see \ref{})}. The relation between the original and converted type is defined by one-step reduction (see \ref{fig:ecore:opsem}). Specifically speaking, if given a judgement $[[G |- e : t2]]$ and relation $[[t1 --> t2]] [[-->]] [[t3]]$, then $[[castup [t1] e]]$ expands the type of $[[e]]$ from $[[t2]]$ to $[[t1]]$, while $[[castdown e]]$ reduces the type of $[[e]]$ from $[[t2]]$ to $[[t3]]$.

Finally, the definition of type equality in \ecore differs from \cc. Without \cc's conversion rule, the type of a term cannot be converted freely against $\beta$-equality, unless using \cast operators. Thus, types of expressions are equal only if they are syntactically equal, i.e. satisfy the $\alpha$-equality.

\begin{figure}
    \ottdefnctx{}
    \ottdefnexpr{}
    \caption{Typing rules of \ecore}
    \label{fig:ecore:typing}
\end{figure}

\subsection{Meta-theory}\label{sec:ecore:meta}
We now discuss the meta-theory of \ecore. We focus on two properties: the decidability of type checking and the type-safety of the language. First, we want to show type checking \ecore is decidable without normalizing property. The type checker will not be stuck by type-level non-termination. Second, the language is type safe, proven by standard subject reduction and progress lemmas.

\subsubsection{Decidability of type checking}
For the decidability, we need to show there exists a type checking algorithm, which never loops forever and returns a unique type for a well-formed expression $[[e]]$. This is done by induction on the length of $[[e]]$ and ranging over typing rules. Most expression typing rules, which have only typing judgements in premises, are already decidable by induction hypothesis. Thus, it is straightforward to follow the syntax-directed judgement to derive a unique type checking result.

The critical case is for rules \ruleref{T\_CastUp} and \ruleref{T\_CastDown}. Both rules contain a premise that needs to judge if two types $[[t1]]$ and $[[t2]]$ follows the one-step reduction, i.e. if $[[t1 --> t2]]$ holds. We need to show such $[[t2]]$ is \emph{unique} with respect to the one-step reduction, or equivalently, reducing $[[t1]]$ by one step will get only a sole result $[[t2]]$. Otherwise, assume $[[e]]:[[t1]]$ and there exists $[[t2']]$ such that $[[t1 --> t2]]$ and $[[t1 --> t2']]$. Then the type of $[[castdown e]]$ can be either $[[t2]]$ or $[[t2']]$ by rule \ruleref{T\_CastDown}, which is not decidable. The property is proven by the following lemma:

\begin{lem}[Uniqueness of one-step reduction]\label{lem:ecore:unique}
	The relation $[[-->]]$, i.e. one-step reduction, is unique in the sense that given $[[e]]$ there is at most one $[[e']]$ such that $[[e --> e']]$.
\end{lem}

\begin{proof}
	By induction on the structure of $[[e]]$.
\end{proof}

With this result, we show a decidable algorithm to check whether one-step relation $[[t1 --> t2]]$ holds. An intuitive algorithm is to reduce the type $[[t1]]$ by one step to obtain $[[t1']]$ (which is unique by Lemma \ref{lem:ecore:unique}), and compare if $[[t1']]$ and $[[t2]]$ are syntactically equal. Thus, checking if $[[t1 --> t2]]$ is decidable and rules \ruleref{T\_CastUp} and \ruleref{T\_CastDown} are therefore decidable. We can conclude the decidability of type checking:

\begin{lem}[Decidability of type checking]\label{lem:ecore:decide}
	There is a decidable algorithm which given $[[G]], [[e]]$ computes the unique $[[t]]$ such that $[[G |- e:t]]$ or reports there is no such $[[t]]$.
\end{lem}

\begin{proof}
	By induction on the structure of $[[e]]$.
\end{proof}

Note that when proving the decidability of type checking, we do not rely on the normalizing property. Because explicit type conversion rules use one-step reduction, which already has a decidable checking algorithm according to Lemma \ref{lem:ecore:unique}. We do not need to further require the normalization of terms. This is different from the proof for \cc which requires the language is normalizing \fixme{[cite the PTS paper]}. Because \cc's conversion rule needs to examine the $\beta$-equivalence of terms, which is decidable only if every term has a normal form.

\subsubsection{n-step cast operators}
Because of the uniqueness of one-step reduction, we can generalize one-step \cast operators to $n$-step. Suppose $[[e]] : [[t]]$ and we have sequences of reduction $[[t1]] [[-->]] [[t2]] [[-->]] \dots [[-->]] [[tn]] [[-->]] [[t]]$ and $[[t]] [[-->]] [[T1]] [[-->]] [[T2]] [[-->]] \dots [[-->]] [[Tn]]$. We can define $n$-step \cast operators as follows:
\begin{flalign*}
    &[[foldn]] [ [[t1]], \dots, [[tn]] ] [[e]] & [[:=]] & [[castup]] [ [[t1]] ] ([[castup]] [ [[t2]] ] (\dots ( [[castup]] [ [[tn]] ] [[e]] ) \dots )) \\
    &[[unfoldn]] [[e]] & [[:=]] & \underbrace{[[castdown]] ([[castdown]] (\dots ( [[castdown]]}_n [[e]]) \dots ))
\end{flalign*}
By rules \ruleref{T\_CastUp} and \ruleref{T\_CastDown}, we have the following typing results:
\[\begin{array}{lll}
    &[[foldn]] [ [[t1]], \dots, [[tn]] ] [[e]] & : [[t1]] \\
    &[[unfoldn]] [[e]] & : [[Tn]]
\end{array}\]

From Lemma \ref{lem:ecore:unique}, we immediately have the following corollary for $n$-step reduction:

\begin{lem}[Uniqueness of $n$-step reduction]\label{lem:ecore:uniquen}
	The $n$-step reduction $[[-->>]]$ is unique in the sense that given $[[e]]$ there is at most one $[[e']]$ such that $[[e]] [[-->>]] [[e']]$.
\end{lem}

\begin{proof}
	Immediate from Lemma \ref{lem:ecore:unique}, by induction on the number of reduction steps.
\end{proof}

Thus, $[[t1]] [[-->>]] [[t]]$ and $[[t]] [[-->>]] [[Tn]]$ are unique by Lemma \ref{lem:ecore:uniquen}. The intermediate types in $[[t1]] [[-->>]] [[t]]$, i.e. $[[t2]], \dots, [[tn]]$, can be uniquely determined. Thus, we can leave them out in the $[[foldn]]$ operator. Finally, we can have $n$-step \cast operators with the following form:
\[\begin{array}{lll}
    &[[foldn [t1] e]] & : [[t1]] \\
    &[[unfoldn e]] & : [[Tn]]
\end{array}\]

\subsubsection{Type-safety}
Proof of the type-safety (or soundness) of \ecore is fairly standard by subject reduction (or preservation) and progress lemmas. The subject reduction proof relies on the substitution lemma. We give the proof sketch of related lemmas as follows:

\begin{lem}[Substitution lemma]\label{lem:ecore:subst}
	If $[[G1, x:T, G2 |- e1:t]]$ and $[[G1 |- e2:T]]$, then $[[G1, G2 [x |-> e2] |- e1[x |-> e2]  : t[x |-> e2] ]]$.
\end{lem}

\begin{proof}
    By induction on the derivation of $[[G1, x:T, G2 |- e1:t]]$.
\end{proof}

\begin{lem}[Subject reduction]\label{lem:ecore:reduct}
If $[[G |- e:T]]$ and $[[e]] [[->>]] e'$ then $[[G |- e':T]]$.
\end{lem}

\begin{proof}
    (\emph{Sketch}) We prove the case for one-step reduction, i.e. $[[e --> e']]$. The lemma can follow by induction on the number of one-step reductions of $[[e]] [[->>]] [[e']]$.
    The proof is by induction with respect to the definition of one-step reduction $[[-->]]$.
\end{proof}

\begin{lem}[Progress]\label{lem:ecore:prog}
If $[[|- e:T]]$ then either $[[e]]$ is a value $v$ or there exists $[[e]]'$ such that $[[e --> e']]$.
\end{lem}

\begin{proof}
    By induction on the derivation of $[[|- e:T]]$.
\end{proof}
